# Meeting Log — 2025-12-28

Recap dettagliato delle attività odierne (pianificazione e prompt Codex) focalizzate sulla verifica automatica del simulatore e sull'estensione delle metriche per controlli Little-family.

---

## 1. Export stage metrics per controlli Little-family (richiesta)
- Confermata la semantica: **backlog = coda DEV**; le metriche di wait/throughput/utilization rimangono invariate.
- Da estendere `simulation/stats.py` (ed eventualmente `simulation/run_sweeps.py` per l'esposizione aggregata) con nuovi campi di sintesi per ogni stage:
  - `avg_servers_<stage> = capacity_time / horizon`
  - `avg_system_length_<stage> = avg_queue_length_<stage> + (avg_servers_<stage> * utilization_<stage>)`
- Obiettivo: scrittura dei nuovi valori in `summary_stats.csv` con ordinamento/descrizioni coerenti, **senza modificare metriche esistenti**.
- DoD esplicito: le nuove colonne compaiono negli output, l'aggregazione continua a funzionare, nessun valore/descrizione preesistente cambia.

## 2. Nuovo entry point CLI di verifica e writer del report
- Definito un eseguibile: `python -m simulation.verify --input <path>`.
- Parametri: `--input`, `--fail-fast`, tolleranze, modalità sweep vs singola run.
- Output previsto: `verification_report.md` nella cartella di output; **exit code non-zero** su failure dure.
- Il writer deve produrre un report riepilogativo (success/failure, difformità rilevate) rispettando l'ordinamento delle verifiche.

## 3. Controlli A/B — file, schema e accounting
- Verifiche preliminari sui file di output:
  - Presenza e parsabilità di `summary_stats.csv` e `tickets_stats.csv`.
  - Schema: colonne obbligatorie per metriche e microdati ticket.
- Accounting cross-file:
  - `tickets_arrived == righe di tickets_stats.csv`.
  - Identificativi ticket univoci.
  - Coerenza temporale (arrivi, inizio servizio, chiusure non decrescenti per ticket).

## 4. Controlli C/D — bounds di dominio e coerenza per-ticket
- Non negatività di tempi e metriche aggregate; `utilization` in [0,1].
- Vincolo di coda: `time_in_system >= total_wait`.
- Regole su cicli: se `cycles == 0` allora `wait` e `service` devono essere ~0 (tolleranza inclusa).
- Decomposizione: `total_wait` ~ somma delle attese per stage.
- Coerenza per-stage: `time_in_system` decomposto in `E[W] + E[S]` con la stessa regola di inclusione.

## 5. Controlli E/F1 — allineamento summary vs microdati
- Definire regola di inclusione ticket/stage (ingresso se `service_time > 0` o `cycles > 0`).
- Calcolare medie micro per attese e confrontarle con le medie in summary.
- Validare per ogni stage la relazione `E[T] ≈ E[W] + E[S]` usando la regola di inclusione.

## 6. Controlli F2 — Little-family su mean jobs (nuove metriche)
- Con i nuovi export `avg_servers` e `avg_system_length` eseguire:
  - Calcolo `Ls = avg_servers * utilization` per ogni stage.
  - Verifica `L ≈ Lq + Ls` usando `avg_system_length` esportato.
- Evidenziare deviazioni oltre tolleranza nel report di verifica.

## 7. Controlli G — modalità sweep e integrità aggregate
- La CLI deve iterare le cartelle esperimento in modalità sweep generando un `verification_report.md` per ciascuna.
- Validare `aggregate_summary.csv` (presenza, schema, coerenza con i summary dei singoli esperimenti).

## 8. Documentazione e test
- Aggiornare/creare `docs/verification.md` (o doc equivalente) con:
  - Uso della CLI, parametri, tolleranze, output previsti.
  - Elenco completo dei controlli A–G e logica di inclusione.
- Possibile harness di test leggero (evitare simulazioni lunghe) per fumare il verificatore.

---

## Decisioni e note operative
- Nessuna implementazione ancora eseguita: sessione dedicata a pianificazione e definizione dei prompt Codex.
- Priorità: 1) export metriche `avg_servers_*` / `avg_system_length_*`; 2) implementare CLI `simulation.verify` con report; 3) codificare controlli A–G.
- La semantica esistente delle metriche non va toccata; backlog resta la coda DEV.

## Next steps
- Implementare le estensioni metriche in `simulation/stats.py` (+ eventuale `run_sweeps.py`) e verificare la scrittura in `summary_stats.csv`.
- Creare modulo `simulation.verify` con parsing CLI, esecuzione dei controlli A–G e generazione di `verification_report.md` (fail-fast opzionale).
- Aggiornare la documentazione di verifica e aggiungere un test rapido per i path critici (schema/bounds/accounting).
